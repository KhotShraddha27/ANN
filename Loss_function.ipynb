{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3RN6Dk6uUsYzC/aVd7lRe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhotShraddha27/ANN/blob/main/Loss_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tvGM53t-HAC",
        "outputId": "323c5b84-0a69-4de2-fd08-94f07d19d3f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss = 1329758547.2835\n",
            "Epoch 100: Loss = 24930191.4859\n",
            "Epoch 200: Loss = 3197792.6354\n",
            "Epoch 300: Loss = 2743265.2698\n",
            "Epoch 400: Loss = 2667787.0187\n",
            "Epoch 500: Loss = 2603079.8409\n",
            "Epoch 600: Loss = 2542096.5968\n",
            "Epoch 700: Loss = 2484259.1259\n",
            "Epoch 800: Loss = 2429193.4096\n",
            "Epoch 900: Loss = 2376599.6792\n",
            "\n",
            "Predicted Price (approx):\n",
            "32136.412949085166\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# Sample dataset: [rooms, area (sqft), location index]\n",
        "X = np.array([\n",
        "    [2, 1200, 0.5],\n",
        "    [3, 1500, 0.7],\n",
        "    [4, 1800, 0.9],\n",
        "    [3, 1600, 0.6],\n",
        "    [5, 2000, 1.0]\n",
        "])\n",
        "\n",
        "# Corresponding house prices (in thousands)\n",
        "Y = np.array([[25000], [30000], [40000], [32000], [50000]])\n",
        "\n",
        "# Normalize features\n",
        "X_mean = np.mean(X, axis=0)\n",
        "X_std = np.std(X, axis=0)\n",
        "X = (X - X_mean) / X_std\n",
        "\n",
        "# Normalize Y if using cross-entropy\n",
        "loss_type = 'mse'\n",
        "\n",
        "if loss_type == 'cross_entropy':\n",
        "    Y_min, Y_max = Y.min(), Y.max()\n",
        "    Y_scaled = (Y - Y_min) / (Y_max - Y_min)\n",
        "else:\n",
        "    Y_scaled = Y.copy()\n",
        "\n",
        "# Weight and bias initialization\n",
        "w = np.random.rand(3, 1)\n",
        "b = np.random.rand(1)\n",
        "lr = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "# Activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Loss functions\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    eps = 1e-15\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    z = np.dot(X, w) + b\n",
        "    # y_pred = sigmoid(z)\n",
        "\n",
        "\n",
        "    if loss_type == 'mse':\n",
        "        y_pred = z;\n",
        "        loss = mse_loss(Y_scaled, y_pred)\n",
        "        d_loss = 2 * (y_pred - Y_scaled) / len(Y)\n",
        "    elif loss_type == 'cross_entropy':\n",
        "        loss = cross_entropy_loss(Y_scaled, y_pred)\n",
        "        d_loss = (y_pred - Y_scaled) * sigmoid_derivative(y_pred)\n",
        "\n",
        "    # Gradients\n",
        "    dw = np.dot(X.T, d_loss)\n",
        "    db = np.sum(d_loss, axis=0)\n",
        "\n",
        "    # Update weights\n",
        "    w -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
        "\n",
        "# Prediction\n",
        "new_input = np.array([[3, 1500, 0.7]])\n",
        "new_input = (new_input - X_mean) / X_std\n",
        "prediction = np.dot(new_input, w) + b\n",
        "\n",
        "\n",
        "print(\"\\nPredicted Price (approx):\")\n",
        "print(prediction[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample features: [keyword_freq, sender_score, email_length]\n",
        "X = np.array([\n",
        "    [3, 0.1, 200],  # Not spam\n",
        "    [10, 0.9, 100], # Spam\n",
        "    [1, 0.2, 150],  # Not spam\n",
        "    [7, 0.8, 120],  # Spam\n",
        "])\n",
        "\n",
        "# Labels\n",
        "Y = np.array([[0], [1], [0], [1]])\n",
        "\n",
        "# Normalize features (optional but helps with learning)\n",
        "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "W = np.random.rand(3, 1)\n",
        "b = np.random.rand(1)\n",
        "lr = 0.1\n",
        "epochs = 1000\n",
        "loss_history = []\n",
        "loss_type = 'cross-entropy'\n",
        "\n",
        "# Activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Loss functions\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    eps = 1e-15\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "# Training function\n",
        "for epoch in range(epochs):\n",
        "    z = np.dot(X, W) + b\n",
        "    y_pred = sigmoid(z)\n",
        "\n",
        "    # Select loss function\n",
        "    if loss_type == 'mse':\n",
        "        loss = mse_loss(Y, y_pred)\n",
        "        d_loss = 2 * (y_pred - Y) * sigmoid_derivative(y_pred)\n",
        "    elif loss_type == 'cross-entropy':\n",
        "        loss = cross_entropy_loss(Y, y_pred)\n",
        "        d_loss = (y_pred - Y) * sigmoid_derivative(y_pred)\n",
        "\n",
        "    # Backpropagation\n",
        "    dw = np.dot(X.T, d_loss)\n",
        "    db = np.sum(d_loss)\n",
        "\n",
        "    W -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"[{loss_type.upper()}] Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "    loss_history.append(loss)\n",
        "\n",
        "output = sigmoid(np.dot(X, W) + b)\n",
        "print(\"\\nFinal Predictions:\")\n",
        "print(output.round())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zFPmBUo-K9K",
        "outputId": "f7d7e2d7-36a8-4eb5-d971-23aba650f817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CROSS-ENTROPY] Epoch 0, Loss: 0.3726\n",
            "[CROSS-ENTROPY] Epoch 100, Loss: 0.0840\n",
            "[CROSS-ENTROPY] Epoch 200, Loss: 0.0583\n",
            "[CROSS-ENTROPY] Epoch 300, Loss: 0.0470\n",
            "[CROSS-ENTROPY] Epoch 400, Loss: 0.0403\n",
            "[CROSS-ENTROPY] Epoch 500, Loss: 0.0357\n",
            "[CROSS-ENTROPY] Epoch 600, Loss: 0.0324\n",
            "[CROSS-ENTROPY] Epoch 700, Loss: 0.0298\n",
            "[CROSS-ENTROPY] Epoch 800, Loss: 0.0277\n",
            "[CROSS-ENTROPY] Epoch 900, Loss: 0.0260\n",
            "\n",
            "Final Predictions:\n",
            "[[0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample Data: [10th%, 12th%, CGPA, IQ]\n",
        "X = np.array([\n",
        "    [85, 80, 8.0, 110],\n",
        "    [70, 65, 6.5, 95],\n",
        "    [90, 88, 9.0, 120],\n",
        "    [60, 58, 5.8, 85],\n",
        "    [75, 70, 7.2, 100]\n",
        "])\n",
        "\n",
        "# Labels: 1 = Placed, 0 = Not Placed\n",
        "Y = np.array([[1], [0], [1], [0], [1]])\n",
        "\n",
        "# Normalize features\n",
        "X_mean = np.mean(X, axis=0)\n",
        "X_std = np.std(X, axis=0)\n",
        "X = (X - X_mean) / X_std\n",
        "\n",
        "# Initialize weights and bias\n",
        "w = np.random.rand(4, 1)\n",
        "b = np.random.rand(1)\n",
        "lr = 0.01\n",
        "epochs = 1000\n",
        "loss_type = 'cross-entropy'\n",
        "\n",
        "# Activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Loss functions\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    eps = 1e-15\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "# Training function\n",
        "for epoch in range(epochs):\n",
        "    z = np.dot(X, w) + b\n",
        "    y_pred = sigmoid(z)\n",
        "\n",
        "    # Select loss function\n",
        "    if loss_type == 'mse':\n",
        "        loss = mse_loss(Y, y_pred)\n",
        "        d_loss = 2 * (y_pred - Y) * sigmoid_derivative(y_pred)\n",
        "    elif loss_type == 'cross-entropy':\n",
        "        loss = cross_entropy_loss(Y, y_pred)\n",
        "        d_loss = (y_pred - Y) * sigmoid_derivative(y_pred)\n",
        "\n",
        "    # Backpropagation\n",
        "    dw = np.dot(X.T, d_loss)\n",
        "    db = np.sum(d_loss)\n",
        "\n",
        "    w -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\" Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "output = sigmoid(np.dot(X, w) + b)\n",
        "print(\"\\nFinal Predictions:\")\n",
        "print(output.round())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ_8vIrq-VsZ",
        "outputId": "837059bc-1bf5-473d-d859-d34a6166d87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch 0, Loss: 0.2582\n",
            " Epoch 100, Loss: 0.2297\n",
            " Epoch 200, Loss: 0.2128\n",
            " Epoch 300, Loss: 0.2011\n",
            " Epoch 400, Loss: 0.1921\n",
            " Epoch 500, Loss: 0.1848\n",
            " Epoch 600, Loss: 0.1785\n",
            " Epoch 700, Loss: 0.1731\n",
            " Epoch 800, Loss: 0.1682\n",
            " Epoch 900, Loss: 0.1638\n",
            "\n",
            "Final Predictions:\n",
            "[[1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data: [Today_Temp, Humidity, WindSpeed]\n",
        "X = np.array([\n",
        "    [30, 70, 10],\n",
        "    [32, 65, 12],\n",
        "    [31, 72, 9],\n",
        "    [29, 75, 8],\n",
        "    [33, 60, 11]\n",
        "])\n",
        "\n",
        "# Target: Next day temperature\n",
        "Y = np.array([[31], [33], [32], [30], [34]])\n",
        "\n",
        "# Normalize input features\n",
        "X_mean = np.mean(X, axis=0)\n",
        "X_std = np.std(X, axis=0)\n",
        "X = (X - X_mean) / X_std\n",
        "\n",
        "loss_type = 'mse'\n",
        "\n",
        "if loss_type == 'cross_entropy':\n",
        "    Y_min, Y_max = Y.min(), Y.max()\n",
        "    Y_scaled = (Y - Y_min) / (Y_max - Y_min)\n",
        "else:\n",
        "    Y_scaled = Y.copy()\n",
        "\n",
        "# Weight and bias initialization\n",
        "w = np.random.rand(3, 1)\n",
        "b = np.random.rand(1)\n",
        "lr = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "# Activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Loss functions\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    eps = 1e-15\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    z = np.dot(X, w) + b\n",
        "    # y_pred = sigmoid(z)\n",
        "\n",
        "\n",
        "    if loss_type == 'mse':\n",
        "        y_pred = z;\n",
        "        loss = mse_loss(Y_scaled, y_pred)\n",
        "        d_loss = 2 * (y_pred - Y_scaled) / len(Y)\n",
        "    elif loss_type == 'cross_entropy':\n",
        "        loss = cross_entropy_loss(Y_scaled, y_pred)\n",
        "        d_loss = (y_pred - Y_scaled) * sigmoid_derivative(y_pred)\n",
        "\n",
        "    # Gradients\n",
        "    dw = np.dot(X.T, d_loss)\n",
        "    db = np.sum(d_loss, axis=0)\n",
        "\n",
        "    # Update weights\n",
        "    w -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
        "\n",
        "#Predict next day temperature\n",
        "new_data = np.array([[31, 68, 10]])  # today's temp, humidity, wind speed\n",
        "new_data = (new_data - X_mean) / X_std\n",
        "prediction = np.dot(new_data, w) + b\n",
        "\n",
        "print(\"\\nForecasted Temperature (°C):\")\n",
        "print(prediction[0][0])"
      ],
      "metadata": {
        "id": "71MsIKRQ-aA5",
        "outputId": "8609733a-1ddd-4331-e4c5-c66099fba59d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss = 1009.5309\n",
            "Epoch 100: Loss = 17.7784\n",
            "Epoch 200: Loss = 0.3269\n",
            "Epoch 300: Loss = 0.0126\n",
            "Epoch 400: Loss = 0.0038\n",
            "Epoch 500: Loss = 0.0021\n",
            "Epoch 600: Loss = 0.0013\n",
            "Epoch 700: Loss = 0.0009\n",
            "Epoch 800: Loss = 0.0006\n",
            "Epoch 900: Loss = 0.0004\n",
            "\n",
            "Forecasted Temperature (°C):\n",
            "32.0040538842271\n"
          ]
        }
      ]
    }
  ]
}